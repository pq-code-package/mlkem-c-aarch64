# SPDX-License-Identifier: Apache-2.0

name: Bench MLKEM-C-AArch64
description: Run benchmarking script

inputs:
  name:
    description: Name for the benchmarking run
    required: true
  perf:
    description: Method of obtaining PMU metrics
    required: true
    default: "PERF"
  cflags:
    description: CFLAGS to pass to compilation
    default: ""
  archflags:
    description: ARCHFLAGS to pass to compilation
    default: ""
  opt:
    description: opt flag to set for tests script
    default: "true"
  bench_extra_args:
    description: Further arguments to be appended to command line for `bench` script
    default: ""
  store_results:
    description: Whether to push results to GH pages
    default: "false"
  gh_token:
    description: GitHub access token
    required: true
  nix-shell:
    description: Run in the specified Nix environment if exists
    default: "ci"
  nix-cache:
    description: Determine whether to enable nix cache
    default: 'false'
  nix-verbose:
    description: Determine wether to suppress nix log or not
    default: 'false'
  custom_shell:
    description: The shell to use. Only relevant if no nix-shell specified
    default: "bash"
  cross_prefix:
    description: "Binary prefix for cross-compilation builds"
    default: ""
runs:
  using: composite
  steps:
    - uses: ./.github/actions/setup-shell
      with:
        nix-shell: ${{ inputs.nix-shell }}
        nix-cache: ${{ inputs.nix-cache }}
        nix-verbose: ${{ inputs.nix-verbose }}
        gh_token: ${{ inputs.gh_token }}
        custom_shell: ${{ inputs.custom_shell }}
        script: |
          ARCH=$(uname -m)
          cat >> $GITHUB_STEP_SUMMARY <<-EOF
            ## Setup
            Architecture: $ARCH
            - $(uname -a)
            - $(nix --version)
            - $(${{ matrix.target.cross_prefix }}gcc --version | grep -m1 "")
            - $(bash --version | grep -m1 "")

            ## CPU Info
            $(cat /proc/cpuinfo)
          EOF
    - name: Run benchmark
      shell: ${{ env.SHELL }}
      run: |
        ./scripts/tests bench -c ${{ inputs.perf }} --cross-prefix="${{ inputs.cross_prefix }}" \
              --cflags="${{ inputs.cflags }}" --arch-flags="${{ inputs.archflags }}" \
              $([[ ${{ inputs.opt }} == "false" ]] && echo "--no-opt")  \
              -v --output=output.json ${{ inputs.bench_extra_args }}

        ./scripts/tests bench --components -c ${{ inputs.perf }} --cross-prefix="${{ inputs.cross_prefix }}" \
              --cflags="${{ inputs.cflags }}" --arch-flags="${{ inputs.archflags }}" \
              $([[ ${{ inputs.opt }} == "false" ]] && echo "--no-opt")  \
              -v --output=output.json ${{ inputs.bench_extra_args }}
    - name: Store benchmark result
      if: ${{ inputs.store_results == 'true' }}
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: ${{ inputs.name }}
        tool: "customSmallerIsBetter"
        output-file-path: output.json
        github-token: ${{ inputs.gh_token }}
        auto-push: true
