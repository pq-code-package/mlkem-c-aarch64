#!/usr/bin/env python
# SPDX-License-Identifier: Apache-2.0

import platform
import sys
import os
import subprocess
import logging
import click
import hashlib
from functools import reduce
from enum import Enum


def config_logger(verbose):
    if verbose:
        logging.basicConfig(
            stream=sys.stdout,
            format="%(levelname)-5s > %(message)s",
            level=logging.DEBUG,
        )
    else:
        logging.basicConfig(
            stream=sys.stdout,
            format="%(levelname)-5s > %(message)s",
            level=logging.INFO,
        )


def sha256sum(result):
    m = hashlib.sha256()
    m.update(result)
    return m.hexdigest()


class TEST_TYPES(Enum):
    MLKEM = 1
    BENCH = 2
    NISTKAT = 3
    KAT = 4
    BENCH_COMPONENTS = 5

    def __str__(self):
        return self.name.lower()

    def desc(self):
        match self:
            case TEST_TYPES.MLKEM:
                return "Functional Test"
            case TEST_TYPES.BENCH:
                return "Benchmark"
            case TEST_TYPES.BENCH_COMPONENTS:
                return "Benchmark Components"
            case TEST_TYPES.NISTKAT:
                return "Nistkat Test"
            case TEST_TYPES.KAT:
                return "Kat Test"

    def bin(self):
        match self:
            case TEST_TYPES.MLKEM:
                return "test_kyber"
            case TEST_TYPES.BENCH:
                return "bench_kyber"
            case TEST_TYPES.BENCH_COMPONENTS:
                return "bench_components_kyber"
            case TEST_TYPES.NISTKAT:
                return "gen_NISTKAT"
            case TEST_TYPES.KAT:
                return "gen_KAT"

    def bin_path(self, scheme):
        return f"test/build/{scheme.name.lower()}/bin/{self.bin()}{scheme.suffix()}"


class SCHEME(Enum):
    MLKEM512 = 1
    MLKEM768 = 2
    MLKEM1024 = 3

    def __str__(self):
        match self:
            case SCHEME.MLKEM512:
                return "ML-KEM-512"
            case SCHEME.MLKEM768:
                return "ML-KEM-768"
            case SCHEME.MLKEM1024:
                return "ML-KEM-1024"

    def suffix(self):
        return self.name.removeprefix("MLKEM")


def base_compile(
    test,
    verbose,
    cross_prefix,
    extra_make_envs={},
    extra_make_args=[],
):
    """compile or cross compile with some extra environment variables and makefile arguments"""

    def dict2str(dict):
        s = ""
        for k, v in dict.items():
            s += f"{k}={v} "
        return s

    logging.debug(f"Compiling {test}...")
    args = [
        "make",
        f"CROSS_PREFIX={cross_prefix}",
        f"{test}",
    ] + extra_make_args

    logging.info(dict2str(extra_make_envs) + " ".join(args))

    p = subprocess.run(
        args,
        stdout=subprocess.DEVNULL if not verbose else None,
        env=os.environ.copy() | extra_make_envs,
    )

    if p.returncode != 0:
        logging.error(f"make failed: {p.returncode}")
        sys.exit(1)


def base_run(
    bin,
    verbose,
    run_as_root=False,
    exec_wrapper=None,
    cross_prefix="",
):
    """Run the binary in all different ways"""
    cmd = [f"./{bin}"]
    if cross_prefix and platform.system() != "Darwin":
        logging.info(f"Emulating {bin} with QEMU")
        if "x86_64" in cross_prefix:
            cmd = ["qemu-x86_64"] + cmd
        elif "aarch64" in cross_prefix:
            cmd = ["qemu-aarch64"] + cmd
        else:
            logging.info(
                f"Emulation for {cross_prefix} on {platform.system()} not supported"
            )

    if run_as_root:
        logging.info(
            f"Running {bin} as root -- you may need to enter your root password."
        )
        cmd = ["sudo"] + cmd

    if exec_wrapper:
        logging.info(f"Running {bin} with customized wrapper.")
        exec_wrapper = exec_wrapper.split(" ")
        cmd = exec_wrapper + cmd

    logging.info(" ".join(cmd))
    result = subprocess.run(
        cmd,
        capture_output=True,
        universal_newlines=False,
    )

    if result.returncode != 0:
        logging.error(
            f"Running '{cmd}' failed: {result.returncode} {result.stderr.decode()}"
        )
        sys.exit(1)

    return result.stdout


def parse_meta(scheme, field):
    result = subprocess.run(
        [
            "yq",
            "-r",
            "--arg",
            "scheme",
            str(scheme),
            f'.implementations.[] | select(.name == $scheme) | ."{field}"',
            "./META.yml",
        ],
        capture_output=True,
        encoding="utf-8",
        universal_newlines=False,
    )
    return result.stdout.strip()


def test_schemes(
    test,
    actual_proc,
    expect_proc,
    process_result,
    verbose,
    cross_prefix,
    run_as_root=False,
    exec_wrapper=None,
):
    """
    :param process_result: process result and return summary
    """
    summary_file = os.environ.get("GITHUB_STEP_SUMMARY")
    summary = f"## {test.desc()}\n"

    fail = False
    results = {}
    for scheme in SCHEME:
        result = base_run(
            test.bin_path(scheme),
            verbose,
            run_as_root,
            exec_wrapper,
            cross_prefix,
        )
        results[scheme] = result

        actual = actual_proc(result)
        expect = expect_proc(scheme)

        f = actual != expect
        s = process_result(f, scheme, result, expect, actual)
        summary += s
        fail = fail or f

    if summary_file is not None:
        with open(summary_file, "a") as f:
            print(summary, file=f)

    if fail:
        sys.exit(1)

    return results


def process_test(fail, scheme, result, expect, actual):
    if fail:
        logging.error(f"{scheme} failed, expecting {expect}, but getting {actual}")
        summary = f":x: {scheme}, expecting {expect}, but getting {actual}\n"
    else:
        logging.info(f"{scheme} passed")
        summary = f":white_check_mark: {scheme}\n"

    return summary


def process_bench(fail, scheme, result, expect, actual):
    logging.info(f"{scheme}")
    logging.info(f"\n{result.decode()}")

    summary = f"{scheme}\n{result.decode()}\n"

    return summary


def process_make_envs(cflags, arch_flags):
    return ({"CFLAGS": f"{cflags}"} if cflags is not None else {}) | (
        {"ARCH_FLAGS": f"{arch_flags}"} if arch_flags is not None else {}
    )


_shared_options = [
    click.option(
        "-v",
        "--verbose",
        is_flag=True,
        show_default=True,
        default=False,
        type=bool,
        help="Show verbose output or not",
    ),
    click.option(
        "-cp",
        "--cross-prefix",
        default="",
        show_default=True,
        nargs=1,
        help="Cross prefix for compilation",
    ),
    click.option(
        "--cflags",
        nargs=1,
        help="Extra cflags to passed in (e.g. '-mcpu=cortex-a72')",
    ),
    click.option(
        "--arch-flags",
        nargs=1,
        help="Extra arch flags to passed in (e.g. '-march=armv8')",
    ),
    click.option(
        "--opt/--no-opt",
        is_flag=True,
        show_default=True,
        default=True,
        help="Choose whether to enable assembly optimizations (if present)",
    ),
    click.option(
        "--auto/--no-auto",
        is_flag=True,
        show_default=True,
        default=True,
        help="Allow makefile to auto configure system specific preprocessor",
    ),
    click.option(
        "--compile/--no-compile",
        is_flag=True,
        show_default=True,
        default=True,
        help="Determine to compile the binary or not",
    ),
    click.option(
        "--run/--no-run",
        is_flag=True,
        show_default=True,
        default=True,
        help="Determine to run the compiled binary or not",
    ),
]

_bench_options = [
    click.option(
        "-c",
        "--cycles",
        nargs=1,
        type=click.Choice(["NO", "PMU", "PERF", "M1"]),
        show_default=True,
        default="NO",
        help="Method for counting clock cycles. PMU requires (user-space) access to the Arm Performance Monitor Unit (PMU). PERF requires a kernel with perf support. M1 only works on Apple silicon.",
    ),
    click.option(
        "-o",
        "--output",
        nargs=1,
        help="Path to output file in json format",
    ),
    click.option(
        "-r",
        "--run-as-root",
        is_flag=True,
        show_default=True,
        default=False,
        type=bool,
        help="Benchmarking binary is run with sudo.",
    ),
    click.option(
        "-w",
        "--exec-wrapper",
        help="Run the benchmark binary with the user-customized wrapper.",
    ),
    click.option(
        "-t",
        "--mac-taskpolicy",
        nargs=1,
        type=click.Choice(["utility", "background", "maintenance"]),
        hidden=platform.system() != "Darwin",
        show_default=True,
        default=None,
        help="Run the program using the specified QoS clamp. Applies to MacOS only. Setting this flag to 'background' guarantees running on E-cores. This is an abbreviation of --exec-wrapper 'taskpolicy -c {mac_taskpolicy}'.",
    ),
    click.option(
        "--components",
        is_flag=True,
        type=bool,
        show_default=True,
        default=False,
        help="Benchmark low-level components",
    ),
]


def add_options(options):
    return lambda func: reduce(lambda f, o: o(f), reversed(options), func)


@click.command(
    short_help="Run the functional tests for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
def func(verbose, cross_prefix, cflags, arch_flags, opt, auto, compile, run):
    config_logger(verbose)

    def expect(scheme):
        sk_bytes = parse_meta(scheme, "length-secret-key")
        pk_bytes = parse_meta(scheme, "length-public-key")
        ct_bytes = parse_meta(scheme, "length-ciphertext")

        return (
            f"CRYPTO_SECRETKEYBYTES:  {sk_bytes}\n"
            + f"CRYPTO_PUBLICKEYBYTES:  {pk_bytes}\n"
            + f"CRYPTO_CIPHERTEXTBYTES: {ct_bytes}\n"
        )

    logging.info(f"{TEST_TYPES.MLKEM.desc()}")

    if compile:
        base_compile(
            TEST_TYPES.MLKEM,
            verbose,
            cross_prefix,
            extra_make_envs=process_make_envs(cflags, arch_flags),
            extra_make_args=[f"OPT={int(opt)}", f"AUTO={int(auto)}"],
        )

    if run:
        test_schemes(
            TEST_TYPES.MLKEM,
            lambda result: str(result, encoding="utf-8"),
            expect,
            process_test,
            verbose,
            cross_prefix,
        )


@click.command(
    short_help="Run the nistkat tests for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
def nistkat(verbose, cross_prefix, cflags, arch_flags, opt, auto, compile, run):
    config_logger(verbose)

    logging.info(f"{TEST_TYPES.NISTKAT.desc()}")

    if compile:
        base_compile(
            TEST_TYPES.NISTKAT,
            verbose,
            cross_prefix,
            extra_make_envs=process_make_envs(cflags, arch_flags),
            extra_make_args=[f"OPT={int(opt)}", f"AUTO={int(auto)}"],
        )

    if run:
        test_schemes(
            TEST_TYPES.NISTKAT,
            sha256sum,
            lambda scheme: parse_meta(scheme, "nistkat-sha256"),
            process_test,
            verbose,
            cross_prefix,
        )


@click.command(
    short_help="Run the kat tests for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
def kat(verbose, cross_prefix, cflags, arch_flags, opt, auto, compile, run):
    config_logger(verbose)

    logging.info(f"{TEST_TYPES.KAT.desc()}")

    if compile:
        base_compile(
            TEST_TYPES.KAT,
            verbose,
            cross_prefix,
            extra_make_envs=process_make_envs(cflags, arch_flags),
            extra_make_args=[f"OPT={int(opt)}", f"AUTO={int(auto)}"],
        )

    if run:
        test_schemes(
            TEST_TYPES.KAT,
            sha256sum,
            lambda scheme: parse_meta(scheme, "kat-sha256"),
            process_test,
            verbose,
            cross_prefix,
        )


@click.command(
    short_help="Run the benchmarks for all parameter sets",
    context_settings={"show_default": True},
)
@add_options(_shared_options)
@add_options(_bench_options)
def bench(
    verbose,
    cycles,
    cross_prefix,
    cflags,
    arch_flags,
    opt,
    auto,
    compile,
    run,
    output,
    run_as_root,
    exec_wrapper,
    mac_taskpolicy,
    components,
):
    config_logger(verbose)

    if mac_taskpolicy:
        if exec_wrapper:
            logging.error(f"cannot set both --mac-taskpolicy and --exec-wrapper")
            sys.exit(1)
        else:
            exec_wrapper = f"taskpolicy -c {mac_taskpolicy}"

    if components is False:
        bench_type = TEST_TYPES.BENCH
    else:
        bench_type = TEST_TYPES.BENCH_COMPONENTS
        output = False

    logging.info(f"{bench_type.desc()}")

    if compile:
        base_compile(
            bench_type,
            verbose,
            cross_prefix,
            extra_make_envs=process_make_envs(cflags, arch_flags),
            extra_make_args=[
                f"CYCLES={cycles}",
                f"OPT={int(opt)}",
                f"AUTO={int(auto)}",
            ],
        )

    if run:
        results = test_schemes(
            bench_type,
            lambda _: True,
            lambda _: True,
            process_bench,
            verbose,
            cross_prefix,
            run_as_root,
            exec_wrapper,
        )

        if output is not None and components is False:
            import json

            with open(output, "w") as f:
                v = []
                for scheme in results:
                    schemeStr = str(scheme)
                    r = results[scheme]

                    # The first 3 lines of the output are expected to be
                    # keypair cycles=X
                    # encaps cycles=X
                    # decaps cycles=X

                    lines = [
                        line.decode() for line in r.splitlines() if "=" in line.decode()
                    ]

                    d = {k: int(v) for k, v in (l.split("=") for l in lines)}
                    for primitive in ["keypair", "encaps", "decaps"]:
                        v.append(
                            {
                                "name": f"{schemeStr} {primitive}",
                                "unit": "cycles",
                                "value": d[f"{primitive} cycles"],
                            }
                        )
                f.write(json.dumps(v))


@click.group(invoke_without_command=True)
def cli():
    pass


cli.add_command(func)
cli.add_command(nistkat)
cli.add_command(kat)
cli.add_command(bench)

if __name__ == "__main__":
    cli()
